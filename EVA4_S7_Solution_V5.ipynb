{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EVA4_S7_Solution-V5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a8b6af372e74cbca6c5c69cc79cf51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e792ae99cb14cfbaa9d4e3f3701e6ef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f541516083d489b94f9d3aece4910fa",
              "IPY_MODEL_dc1b1fde32354359ace1ef8382801778"
            ]
          }
        },
        "4e792ae99cb14cfbaa9d4e3f3701e6ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f541516083d489b94f9d3aece4910fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0c21b1a50894dbfa097392afe928c4f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09652bf54869474990b613e0eb56fff5"
          }
        },
        "dc1b1fde32354359ace1ef8382801778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13a58aeceb2c43b4a49d0f21b8bdd668",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:04, 41983557.43it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_102a0cedb59d406d91a1b753662e8fec"
          }
        },
        "e0c21b1a50894dbfa097392afe928c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09652bf54869474990b613e0eb56fff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13a58aeceb2c43b4a49d0f21b8bdd668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "102a0cedb59d406d91a1b753662e8fec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujitojha1/S7/blob/master/EVA4_S7_Solution_V5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HF57VAaEaZOp"
      },
      "source": [
        "# Problem Statement EVA 4, Session7 : CIFAR 10\n",
        "\n",
        "**Target**: \n",
        "\n",
        "\n",
        "*   Achieve 80% accuracy with Params < 1M for CIFAR10 dataset image classification\n",
        "*   Use C1 -> C2 -> C3 -> C4 -> O architecture\n",
        "*   Model should have receptive field more than 44\n",
        "*   Should have one layer depthwise separable convolution and dialted convolution\n",
        "\n",
        "**Results**\n",
        "\n",
        "**Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R_cubGn4bSpS"
      },
      "source": [
        "## 1. Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s214Xt6MyYZ",
        "colab_type": "code",
        "outputId": "9b58caee-c047-427b-d32e-d3eb970a59e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "# Torch libraries\n",
        "import torch                   #PyTorch base libraries\n",
        "import torch.nn as nn          #nn libraries to define the architecture as object\n",
        "import torch.nn.functional as F  #To define the functional for all computations\n",
        "import torch.optim as optim    #Optimizatin functions like SGD, ADAMS,\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "\n",
        "# Taskbar progression\n",
        "import tqdm as tqdm\n",
        "\n",
        "# Torch summary for pytorch\n",
        "!pip install torchsummary\n",
        "import torchsummary as summary\n",
        "\n",
        "# Plottting libraries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3MUaLty4aCIM"
      },
      "source": [
        "## 2. Loading train and test data with transforms and loader functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCs270BiMyYk",
        "colab_type": "code",
        "outputId": "1c33c689-f47c-4c61-9ccf-ae44d8e57aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "1a8b6af372e74cbca6c5c69cc79cf51c",
            "4e792ae99cb14cfbaa9d4e3f3701e6ef",
            "4f541516083d489b94f9d3aece4910fa",
            "dc1b1fde32354359ace1ef8382801778",
            "e0c21b1a50894dbfa097392afe928c4f",
            "09652bf54869474990b613e0eb56fff5",
            "13a58aeceb2c43b4a49d0f21b8bdd668",
            "102a0cedb59d406d91a1b753662e8fec"
          ]
        }
      },
      "source": [
        "# Defining CUDA\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "print(\"CUDA availability ?\",cuda)\n",
        "\n",
        "\n",
        "# Transformations in training phase\n",
        "train_transform = transforms.Compose([\n",
        "                                      transforms.RandomCrop(32, padding=4),\n",
        "#                                       transforms.RandomHorizontalFlip(),\n",
        "#                                       transforms.RandomRotation(10),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                                      ])\n",
        "\n",
        "# Transformations in testing phase\n",
        "test_transform = transforms.Compose([\n",
        "#                                      transforms.RandomCrop(32, padding=4),\n",
        "#                                      transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                                     ])\n",
        "\n",
        "# Loading train data\n",
        "train = datasets.CIFAR10('./Data',train=True,transform=train_transform,download=True)\n",
        "\n",
        "# Loading test data\n",
        "test = datasets.CIFAR10('./Data',train=False, transform=test_transform,download=True)\n",
        "\n",
        "# Defining data loaders with setting\n",
        "dataloaders_args = dict(shuffle=True, batch_size=128, num_workers = 4, pin_memory = True) if cuda else dict(shuffle=True,batch_size=64)\n",
        "\n",
        "# Train dataloader\n",
        "trainloader = torch.utils.data.DataLoader(train, **dataloaders_args)\n",
        "\n",
        "# Test dataloader\n",
        "testloader = torch.utils.data.DataLoader(test, **dataloaders_args)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA availability ? True\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./Data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a8b6af372e74cbca6c5c69cc79cf51c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./Data/cifar-10-python.tar.gz to ./Data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XPxWjYERcOSU"
      },
      "source": [
        "## 3. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dw0F_A8tcZWI"
      },
      "source": [
        "### 3.1 Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n43anKs5MyYs",
        "colab_type": "code",
        "outputId": "0d2a82e1-22dd-467f-ffe7-b6b717352c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Load train data as numpy array\n",
        "train_data = train.data\n",
        "test_data = test.data\n",
        "\n",
        "total_data = np.concatenate((train_data, test_data), axis=0)\n",
        "print(total_data.shape)\n",
        "print(total_data.mean(axis=(0,1,2))/255)\n",
        "print(total_data.std(axis=(0,1,2))/255)\n",
        "#print(vars(train))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 32, 32, 3)\n",
            "[0.49186878 0.48265391 0.44717728]\n",
            "[0.24697121 0.24338894 0.26159259]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCsUyZ-8MyYx",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Plotting sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StVZow1tMyYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "\n",
        "# # get some random training images\n",
        "# dataiter = iter(train_loader)\n",
        "# images,labels = dataiter.next()\n",
        "\n",
        "# # Show images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# # print labels\n",
        "# print(' '.join('%10s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK0ANxADMyY4",
        "colab_type": "text"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6naKff4adJIP",
        "colab": {}
      },
      "source": [
        "dropout_value = 0.1\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 32\n",
        "        #o/p size=32*32*32 RF=3\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3),dilation=2, padding=2, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 32\n",
        "        #o/p size=64*32*32 RF=5\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 32\n",
        "        #o/p size=64*32*32 RF=5\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n",
        "         #o/p size=64*16*16 RF=6\n",
        "        \n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), groups=64,padding=1, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 16\n",
        "        #o/p size =64*16*16 RF=10\n",
        "#         self.convblock5 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "#             nn.ReLU(),            \n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.Dropout(dropout_value)\n",
        "#         ) # output_size = 16\n",
        "        #o/p size = 128*16*16 RF = 14\n",
        "                # TRANSITION BLOCK 2\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 16\n",
        "        #o/p size=128*16*16 RF=14\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 8\n",
        "         #o/p size=128*8*8 RF=16\n",
        "            \n",
        "        # CONVOLUTION BLOCK 3       \n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3),groups=128, padding=1, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 8\n",
        "        #o/p size = 128*8*8 RF = 24\n",
        "        \n",
        "#         self.convblock8 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n",
        "#             nn.ReLU(),            \n",
        "#             nn.BatchNorm2d(128),\n",
        "#             nn.Dropout(dropout_value)\n",
        "#         ) # output_size = 8\n",
        "        \n",
        "        #o/p size = 256*8*8 RF = 32\n",
        "        # TRANSITION BLOCK 3\n",
        "        self.convblock9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 8\n",
        "        #o/p size=256*8*8 RF=32\n",
        "        self.pool3 = nn.MaxPool2d(2, 2) # output_size = 8\n",
        "         #o/p size=256*4*4 RF=36\n",
        "            \n",
        "        # CONVOLUTION BLOCK 4       \n",
        "        self.convblock10 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 4\n",
        "        #o/p size = 256*4*4 RF = 52\n",
        "        \n",
        "        self.convblock11 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 4\n",
        "        #o/p size = 512*4*4 RF = 68\n",
        "                  \n",
        "        \n",
        "        \n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=4)\n",
        "        ) # output_size = 1\n",
        "        #o/p size = 512*1*1 RF = 92\n",
        "\n",
        "        self.convblock12 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            # nn.BatchNorm2d(10),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        ) \n",
        "        #o/p size = 10*1*1 RF = 32\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_value)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock4(x)\n",
        "#         x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.convblock7(x)\n",
        "#         x = self.convblock8(x)\n",
        "        x = self.convblock9(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.convblock10(x)\n",
        "        x = self.convblock11(x)\n",
        "        x = self.gap(x)        \n",
        "        x = self.convblock12(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YicBoIWRMyY-",
        "colab_type": "text"
      },
      "source": [
        "# Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyP7txXMMyZA",
        "colab_type": "code",
        "outputId": "e2380f8c-e32d-4541-a3b9-bdcecf7ff162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "net = Net().to(device)\n",
        "summary(net, input_size=(3, 32, 32))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "              ReLU-2           [-1, 64, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 64, 32, 32]             128\n",
            "           Dropout-4           [-1, 64, 32, 32]               0\n",
            "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "       BatchNorm2d-7           [-1, 64, 32, 32]             128\n",
            "           Dropout-8           [-1, 64, 32, 32]               0\n",
            "            Conv2d-9           [-1, 64, 32, 32]           4,096\n",
            "        MaxPool2d-10           [-1, 64, 16, 16]               0\n",
            "           Conv2d-11           [-1, 64, 16, 16]             576\n",
            "             ReLU-12           [-1, 64, 16, 16]               0\n",
            "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
            "          Dropout-14           [-1, 64, 16, 16]               0\n",
            "           Conv2d-15          [-1, 128, 16, 16]           8,192\n",
            "        MaxPool2d-16            [-1, 128, 8, 8]               0\n",
            "           Conv2d-17            [-1, 128, 8, 8]           1,152\n",
            "             ReLU-18            [-1, 128, 8, 8]               0\n",
            "      BatchNorm2d-19            [-1, 128, 8, 8]             256\n",
            "          Dropout-20            [-1, 128, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]          32,768\n",
            "        MaxPool2d-22            [-1, 256, 4, 4]               0\n",
            "           Conv2d-23            [-1, 256, 4, 4]         589,824\n",
            "             ReLU-24            [-1, 256, 4, 4]               0\n",
            "      BatchNorm2d-25            [-1, 256, 4, 4]             512\n",
            "          Dropout-26            [-1, 256, 4, 4]               0\n",
            "           Conv2d-27            [-1, 512, 4, 4]         131,072\n",
            "             ReLU-28            [-1, 512, 4, 4]               0\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "          Dropout-30            [-1, 512, 4, 4]               0\n",
            "        AvgPool2d-31            [-1, 512, 1, 1]               0\n",
            "           Conv2d-32             [-1, 10, 1, 1]           5,120\n",
            "================================================================\n",
            "Total params: 813,568\n",
            "Trainable params: 813,568\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.22\n",
            "Params size (MB): 3.10\n",
            "Estimated Total Size (MB): 9.34\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7mBK94YMyZE",
        "colab_type": "text"
      },
      "source": [
        "# Define a Loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SucwmN1yMyZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht1r3cpiMyZJ",
        "colab_type": "text"
      },
      "source": [
        "# Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KBfdFRQMyZK",
        "colab_type": "code",
        "outputId": "1ea52e0e-4202-45ca-a352-b00802d1b330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for epoch in range(21):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs,labels = inputs.to(device),labels.to(device)\n",
        "        \n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSVSmIPbMyZO",
        "colab_type": "text"
      },
      "source": [
        "# display an image from the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1dR2XwoMyZQ",
        "colab_type": "code",
        "outputId": "791e7efa-e21b-482f-86ea-c104395876ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images[0:4]))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:  truck   car   car  bird\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlJiiL3BFUZSYoi9wRVGUmPI/eqm1WRpk5XEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ5p2CWiMyZV",
        "colab_type": "text"
      },
      "source": [
        "# Prediction of sampe test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAKBmNJ7MyZX",
        "colab_type": "code",
        "outputId": "16bcf76c-cfbf-4bfb-b3d0-6dd4480cdf1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images,labels = images.to(device),labels.to(device)\n",
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:  truck   car   car  bird\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWxn-r1-MyZa",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating Train Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK3IMQSbMyZb",
        "colab_type": "code",
        "outputId": "d82ddbb9-001e-463b-d66c-faf07df43df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 50000 train images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 50000 train images: 81 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfoHnR29MyZg",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BByE5SCnMyZh",
        "colab_type": "code",
        "outputId": "97dd6ec1-beff-47de-f5a5-17def9e8f453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 81 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cns1i5dGMyZn",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating test Accuracy over different classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSrU9MsOMyZo",
        "colab_type": "code",
        "outputId": "994de98d-3a0e-4462-b702-a263e43978ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 65 %\n",
            "Accuracy of   car : 81 %\n",
            "Accuracy of  bird : 65 %\n",
            "Accuracy of   cat : 72 %\n",
            "Accuracy of  deer : 76 %\n",
            "Accuracy of   dog : 53 %\n",
            "Accuracy of  frog : 96 %\n",
            "Accuracy of horse : 86 %\n",
            "Accuracy of  ship : 76 %\n",
            "Accuracy of truck : 84 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yViWXHVEMyZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}