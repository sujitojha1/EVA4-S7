{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EVA4_S7_Solution-V4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujitojha1/S7/blob/master/EVA4_S7_Solution_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HF57VAaEaZOp"
      },
      "source": [
        "# Problem Statement EVA 4, Session7 : CIFAR 10\n",
        "\n",
        "**Target**: \n",
        "\n",
        "\n",
        "*   Achieve 80% accuracy with Params < 1M for CIFAR10 dataset image classification\n",
        "*   Use C1 -> C2 -> C3 -> C4 -> O architecture\n",
        "*   Model should have receptive field more than 44\n",
        "*   Should have one layer depthwise separable convolution and dialted convolution\n",
        "\n",
        "**Results**\n",
        "\n",
        "**Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R_cubGn4bSpS"
      },
      "source": [
        "## 1. Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s214Xt6MyYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d0e0d84-108d-49a7-de2e-30938c09a271"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "# Torch libraries\n",
        "import torch                   #PyTorch base libraries\n",
        "import torch.nn as nn          #nn libraries to define the architecture as object\n",
        "import torch.nn.functional as F  #To define the functional for all computations\n",
        "import torch.optim as optim    #Optimizatin functions like SGD, ADAMS,\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "\n",
        "# Taskbar progression\n",
        "import tqdm as tqdm\n",
        "\n",
        "# Torch summary for pytorch\n",
        "!pip install torchsummary\n",
        "import torchsummary as summary\n",
        "\n",
        "# Plottting libraries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3MUaLty4aCIM"
      },
      "source": [
        "## 2. Loading train and test data with transforms and loader functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCs270BiMyYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "381e6b63-8daa-497e-9490-72cdf207b5ad"
      },
      "source": [
        "# Defining CUDA\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "print(\"CUDA availability ?\",cuda)\n",
        "\n",
        "\n",
        "# Transformations in training phase\n",
        "train_transform = transforms.Compose([\n",
        "                                      transforms.RandomCrop(32, padding=4),\n",
        "#                                       transforms.RandomHorizontalFlip(),\n",
        "#                                       transforms.RandomRotation(10),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                                      ])\n",
        "\n",
        "# Transformations in testing phase\n",
        "test_transform = transforms.Compose([\n",
        "#                                      transforms.RandomCrop(32, padding=4),\n",
        "#                                      transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                                     ])\n",
        "\n",
        "# Loading train data\n",
        "train = datasets.CIFAR10('./Data',train=True,transform=train_transform,download=True)\n",
        "\n",
        "# Loading test data\n",
        "test = datasets.CIFAR10('./Data',train=False, transform=test_transform,download=True)\n",
        "\n",
        "# Defining data loaders with setting\n",
        "dataloaders_args = dict(shuffle=True, batch_size=128, num_workers = 4, pin_memory = True) if cuda else dict(shuffle=True,batch_size=64)\n",
        "\n",
        "# Train dataloader\n",
        "trainloader = torch.utils.data.DataLoader(train, **dataloaders_args)\n",
        "\n",
        "# Test dataloader\n",
        "testloader = torch.utils.data.DataLoader(test, **dataloaders_args)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA availability ? True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XPxWjYERcOSU"
      },
      "source": [
        "## 3. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dw0F_A8tcZWI"
      },
      "source": [
        "### 3.1 Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n43anKs5MyYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "463d3527-dcf5-480c-986e-115335cc7d49"
      },
      "source": [
        "# Load train data as numpy array\n",
        "train_data = train.data\n",
        "test_data = test.data\n",
        "\n",
        "total_data = np.concatenate((train_data, test_data), axis=0)\n",
        "print(total_data.shape)\n",
        "print(total_data.mean(axis=(0,1,2))/255)\n",
        "print(total_data.std(axis=(0,1,2))/255)\n",
        "#print(vars(train))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 32, 32, 3)\n",
            "[0.49186878 0.48265391 0.44717728]\n",
            "[0.24697121 0.24338894 0.26159259]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCsUyZ-8MyYx",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Plotting sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StVZow1tMyYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "\n",
        "# # get some random training images\n",
        "# dataiter = iter(train_loader)\n",
        "# images,labels = dataiter.next()\n",
        "\n",
        "# # Show images\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# # print labels\n",
        "# print(' '.join('%10s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK0ANxADMyY4",
        "colab_type": "text"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6naKff4adJIP",
        "colab": {}
      },
      "source": [
        "dropout_value = 0.1\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 32\n",
        "        #o/p size=32*32*32 RF=3\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3),dilation=2, groups=64, padding=2, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 32\n",
        "        #o/p size=64*32*32 RF=5\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 32\n",
        "        #o/p size=64*32*32 RF=5\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n",
        "         #o/p size=64*16*16 RF=6\n",
        "        \n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), groups=128,padding=1, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 16\n",
        "        #o/p size =64*16*16 RF=10\n",
        "#         self.convblock5 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "#             nn.ReLU(),            \n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.Dropout(dropout_value)\n",
        "#         ) # output_size = 16\n",
        "        #o/p size = 128*16*16 RF = 14\n",
        "                # TRANSITION BLOCK 2\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 16\n",
        "        #o/p size=128*16*16 RF=14\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 8\n",
        "         #o/p size=128*8*8 RF=16\n",
        "            \n",
        "        # CONVOLUTION BLOCK 3       \n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3),groups=128, padding=1, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 8\n",
        "        #o/p size = 128*8*8 RF = 24\n",
        "        \n",
        "#         self.convblock8 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n",
        "#             nn.ReLU(),            \n",
        "#             nn.BatchNorm2d(128),\n",
        "#             nn.Dropout(dropout_value)\n",
        "#         ) # output_size = 8\n",
        "        \n",
        "        #o/p size = 256*8*8 RF = 32\n",
        "        # TRANSITION BLOCK 3\n",
        "        self.convblock9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 8\n",
        "        #o/p size=256*8*8 RF=32\n",
        "        self.pool3 = nn.MaxPool2d(2, 2) # output_size = 8\n",
        "         #o/p size=256*4*4 RF=36\n",
        "            \n",
        "        # CONVOLUTION BLOCK 4       \n",
        "        self.convblock10 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 4\n",
        "        #o/p size = 256*4*4 RF = 52\n",
        "        \n",
        "        self.convblock11 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 4\n",
        "        #o/p size = 512*4*4 RF = 68\n",
        "                  \n",
        "        \n",
        "        \n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=4)\n",
        "        ) # output_size = 1\n",
        "        #o/p size = 512*1*1 RF = 92\n",
        "\n",
        "        self.convblock12 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            # nn.BatchNorm2d(10),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        ) \n",
        "        #o/p size = 10*1*1 RF = 32\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_value)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock4(x)\n",
        "#         x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.convblock7(x)\n",
        "#         x = self.convblock8(x)\n",
        "        x = self.convblock9(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.convblock10(x)\n",
        "        x = self.convblock11(x)\n",
        "        x = self.gap(x)        \n",
        "        x = self.convblock12(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YicBoIWRMyY-",
        "colab_type": "text"
      },
      "source": [
        "# Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyP7txXMMyZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "a1a08304-8a47-428f-9f4c-3799ef38a76d"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "net = Net().to(device)\n",
        "summary(net, input_size=(3, 32, 32))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "              ReLU-2           [-1, 64, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 64, 32, 32]             128\n",
            "           Dropout-4           [-1, 64, 32, 32]               0\n",
            "            Conv2d-5          [-1, 128, 32, 32]           1,152\n",
            "              ReLU-6          [-1, 128, 32, 32]               0\n",
            "       BatchNorm2d-7          [-1, 128, 32, 32]             256\n",
            "           Dropout-8          [-1, 128, 32, 32]               0\n",
            "            Conv2d-9          [-1, 128, 32, 32]          16,384\n",
            "        MaxPool2d-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]           1,152\n",
            "             ReLU-12          [-1, 128, 16, 16]               0\n",
            "      BatchNorm2d-13          [-1, 128, 16, 16]             256\n",
            "          Dropout-14          [-1, 128, 16, 16]               0\n",
            "           Conv2d-15          [-1, 128, 16, 16]          16,384\n",
            "        MaxPool2d-16            [-1, 128, 8, 8]               0\n",
            "           Conv2d-17            [-1, 128, 8, 8]           1,152\n",
            "             ReLU-18            [-1, 128, 8, 8]               0\n",
            "      BatchNorm2d-19            [-1, 128, 8, 8]             256\n",
            "          Dropout-20            [-1, 128, 8, 8]               0\n",
            "           Conv2d-21            [-1, 128, 8, 8]          16,384\n",
            "        MaxPool2d-22            [-1, 128, 4, 4]               0\n",
            "           Conv2d-23            [-1, 256, 4, 4]         294,912\n",
            "             ReLU-24            [-1, 256, 4, 4]               0\n",
            "      BatchNorm2d-25            [-1, 256, 4, 4]             512\n",
            "          Dropout-26            [-1, 256, 4, 4]               0\n",
            "           Conv2d-27            [-1, 256, 4, 4]         589,824\n",
            "             ReLU-28            [-1, 256, 4, 4]               0\n",
            "      BatchNorm2d-29            [-1, 256, 4, 4]             512\n",
            "          Dropout-30            [-1, 256, 4, 4]               0\n",
            "        AvgPool2d-31            [-1, 256, 1, 1]               0\n",
            "           Conv2d-32             [-1, 10, 1, 1]           2,560\n",
            "================================================================\n",
            "Total params: 943,552\n",
            "Trainable params: 943,552\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 9.14\n",
            "Params size (MB): 3.60\n",
            "Estimated Total Size (MB): 12.75\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7mBK94YMyZE",
        "colab_type": "text"
      },
      "source": [
        "# Define a Loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SucwmN1yMyZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht1r3cpiMyZJ",
        "colab_type": "text"
      },
      "source": [
        "# Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KBfdFRQMyZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80cf7f46-bf70-47be-c7c6-31454b445d91"
      },
      "source": [
        "for epoch in range(21):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs,labels = inputs.to(device),labels.to(device)\n",
        "        \n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSVSmIPbMyZO",
        "colab_type": "text"
      },
      "source": [
        "# display an image from the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1dR2XwoMyZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "a643850e-3235-4795-e1d2-9ca8dda95993"
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images[0:4]))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:  truck  bird truck horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ5p2CWiMyZV",
        "colab_type": "text"
      },
      "source": [
        "# Prediction of sampe test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAKBmNJ7MyZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60545c67-809d-444e-ccc6-91837072b4b6"
      },
      "source": [
        "images,labels = images.to(device),labels.to(device)\n",
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:  truck   dog truck horse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWxn-r1-MyZa",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating Train Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK3IMQSbMyZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea55ae7b-f9af-47ac-d23e-0918ae0fe0b1"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 50000 train images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 50000 train images: 82 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfoHnR29MyZg",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BByE5SCnMyZh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af23bf6c-3e89-4a11-912e-0fb76916a741"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 81 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cns1i5dGMyZn",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating test Accuracy over different classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSrU9MsOMyZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8025ee1e-e093-4e5a-8702-bc488f9f71cc"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 66 %\n",
            "Accuracy of   car : 90 %\n",
            "Accuracy of  bird : 67 %\n",
            "Accuracy of   cat : 66 %\n",
            "Accuracy of  deer : 86 %\n",
            "Accuracy of   dog : 62 %\n",
            "Accuracy of  frog : 85 %\n",
            "Accuracy of horse : 84 %\n",
            "Accuracy of  ship : 90 %\n",
            "Accuracy of truck : 92 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yViWXHVEMyZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}